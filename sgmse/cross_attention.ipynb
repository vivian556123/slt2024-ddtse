{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalGraph(nn.Module):\n",
    "    def __init__(self, hidden_size, attention_head_size=None, num_attention_heads=1):\n",
    "        super(GlobalGraph, self).__init__()\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.attention_head_size = hidden_size // num_attention_heads if attention_head_size is None else attention_head_size\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    " \n",
    "        self.num_qkv = 1\n",
    " \n",
    "        self.query = nn.Linear(hidden_size, self.all_head_size * self.num_qkv)\n",
    "        self.key = nn.Linear(hidden_size, self.all_head_size * self.num_qkv)\n",
    "        self.value = nn.Linear(hidden_size, self.all_head_size * self.num_qkv)\n",
    " \n",
    "    def get_extended_attention_mask(self, attention_mask):\n",
    "        \"\"\"\n",
    "        1 in attention_mask stands for doing attention, 0 for not doing attention.\n",
    "        After this function, 1 turns to 0, 0 turns to -10000.0\n",
    "        Because the -10000.0 will be fed into softmax and -10000.0 can be thought as 0 in softmax.\n",
    "        \"\"\"\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1)\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        return extended_attention_mask\n",
    " \n",
    "    def transpose_for_scores(self, x):\n",
    "        sz = x.size()[:-1] + (self.num_attention_heads,\n",
    "                              self.attention_head_size)\n",
    "        # (batch, max_vector_num, head, head_size)\n",
    "        x = x.view(*sz)\n",
    "        # (batch, head, max_vector_num, head_size)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    " \n",
    "    def forward(self, hidden_states, attention_mask=None, return_scores=False):\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = nn.functional.linear(hidden_states, self.key.weight)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    " \n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    " \n",
    "        attention_scores = torch.matmul(\n",
    "            query_layer / math.sqrt(self.attention_head_size), key_layer.transpose(-1, -2))\n",
    "        if attention_mask is not None:\n",
    "            attention_scores = attention_scores + self.get_extended_attention_mask(attention_mask)\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[\n",
    "                                  :-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        if return_scores:\n",
    "            attention_probs = torch.squeeze(attention_probs, dim=1)\n",
    "            return context_layer, attention_probs\n",
    "        return context_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CrossAttention(GlobalGraph):\n",
    "    def __init__(self, hidden_size, attention_head_size=None, num_attention_heads=1, key_hidden_size=None, query_hidden_size=None):\n",
    "        super(CrossAttention, self).__init__(hidden_size, attention_head_size, num_attention_heads)\n",
    "        if query_hidden_size is not None:\n",
    "            self.query = nn.Linear(query_hidden_size, self.all_head_size * self.num_qkv)\n",
    "        if key_hidden_size is not None:\n",
    "            self.key = nn.Linear(key_hidden_size, self.all_head_size * self.num_qkv)\n",
    "            self.value = nn.Linear(key_hidden_size, self.all_head_size * self.num_qkv)\n",
    " \n",
    "    def forward(self, hidden_states_query, hidden_states_key=None, attention_mask=None, return_scores=False):\n",
    "        mixed_query_layer = self.query(hidden_states_query)\n",
    "        mixed_key_layer = self.key(hidden_states_key)\n",
    "        mixed_value_layer = self.value(hidden_states_key)\n",
    " \n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    " \n",
    "        attention_scores = torch.matmul(\n",
    "            query_layer / math.sqrt(self.attention_head_size), key_layer.transpose(-1, -2))\n",
    "        if attention_mask is not None:\n",
    "            assert hidden_states_query.shape[1] == attention_mask.shape[1] \\\n",
    "                   and hidden_states_key.shape[1] == attention_mask.shape[2]\n",
    "            attention_scores = attention_scores +    self.get_extended_attention_mask(attention_mask)\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[\n",
    "                                  :-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        if return_scores:\n",
    "            return context_layer, torch.squeeze(attention_probs, dim=1)\n",
    "        return context_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_attention = CrossAttention(512)\n",
    "a = torch.randn(2,66666,512)\n",
    "b = torch.randn(2,1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cross_attention( hidden_states_query=a, hidden_states_key=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6470, -1.3187, -0.1688,  ...,  1.1961, -1.7335, -1.7147],\n",
      "        [ 0.2732, -0.3632,  0.0078,  ...,  0.0604,  1.7235, -2.3359],\n",
      "        [-0.6915, -0.3437,  1.6290,  ..., -1.4262,  1.3686,  1.3066],\n",
      "        ...,\n",
      "        [-0.0083, -1.8599, -0.7296,  ...,  0.2520,  0.6743,  1.5492],\n",
      "        [ 1.7215,  0.8142,  0.1106,  ...,  0.7680, -0.8425,  1.7809],\n",
      "        [ 0.2066,  0.1040, -0.1978,  ..., -1.3924, -1.0080,  0.9363]])\n",
      "tensor([[-4.7907e-01,  2.8597e-01,  5.3855e-01,  2.1160e-01, -2.4862e-01,\n",
      "         -5.8863e-01,  1.0730e+00,  1.9546e+00,  1.1577e+00, -3.3469e-01,\n",
      "          1.6733e+00,  2.9119e-01, -1.8771e-01,  1.6734e+00, -6.8469e-01,\n",
      "          4.2377e-01, -2.2570e-01,  6.0401e-01,  6.0938e-01,  8.2346e-01,\n",
      "         -3.7224e-02,  1.8667e-01, -3.1069e-02,  4.0793e-01,  5.0892e-01,\n",
      "         -2.3262e-01,  3.5800e-01,  2.0616e+00,  5.8345e-01,  6.5544e-01,\n",
      "         -2.7921e-01,  1.9590e-01,  4.4828e-01,  1.8016e-01, -8.3591e-01,\n",
      "          1.5395e+00,  2.8855e-01, -2.3225e-01,  1.8388e-03,  2.8844e-01,\n",
      "          1.2631e+00, -1.6503e+00,  7.0251e-01,  2.0267e+00, -2.3873e+00,\n",
      "         -4.5665e-01,  1.3712e+00, -2.5285e+00, -1.1446e-01,  1.4658e+00,\n",
      "         -2.1040e-01, -5.2028e-01, -1.3930e-01, -3.8652e-01, -8.8240e-01,\n",
      "          7.9244e-01, -1.0077e+00,  8.8464e-01, -3.4776e-01, -1.8289e+00,\n",
      "          9.5536e-01, -5.6047e-01, -7.9988e-01,  5.0291e-01, -1.3704e+00,\n",
      "         -1.9820e+00, -1.1908e+00,  1.4171e+00, -2.7030e-01, -1.5780e+00,\n",
      "          3.1448e-01,  1.4296e+00, -1.8363e-01,  2.7779e-01,  1.1855e+00,\n",
      "         -1.9054e+00, -9.7521e-03, -2.2161e-01,  1.1979e+00,  8.2142e-01,\n",
      "          1.5900e+00,  3.3803e-01, -1.0850e+00, -6.6143e-01,  1.8836e+00,\n",
      "          5.8648e-01,  9.5458e-01,  1.2191e+00,  9.3578e-01,  5.6575e-01,\n",
      "         -1.5257e+00, -7.4414e-02,  4.9443e-01, -1.2494e+00,  5.5100e-01,\n",
      "         -1.3956e-01, -1.0732e+00, -4.2378e-01,  8.0229e-01, -7.8265e-01,\n",
      "          7.2048e-01, -1.5901e+00,  7.9743e-02,  9.4151e-01, -1.6158e-01,\n",
      "         -1.8210e-01,  2.5271e-01, -6.7438e-01,  2.7237e-01,  9.2295e-01,\n",
      "         -1.2431e+00, -1.2380e+00,  1.2667e+00,  1.3471e-01,  7.0667e-01,\n",
      "         -9.6047e-01, -5.2228e-01,  1.5753e-01, -1.5343e-01, -6.9211e-01,\n",
      "          8.9735e-01,  1.4104e+00,  2.3612e+00,  9.4566e-01, -2.4078e-01,\n",
      "          6.4710e-01,  6.7836e-01, -2.6071e+00,  1.5192e+00,  8.3474e-01,\n",
      "          2.0220e+00,  1.3176e+00,  6.1271e-01,  7.0167e-01, -6.5305e-01,\n",
      "          2.2249e+00,  8.4877e-01, -5.6163e-02,  9.6760e-01, -6.6176e-01,\n",
      "          1.9110e+00, -1.8948e+00, -4.4650e-01, -1.1264e+00,  4.3765e-01,\n",
      "          4.1629e-01, -4.8369e-01,  1.1042e+00,  7.6040e-01, -4.6297e-01,\n",
      "         -6.7902e-01, -2.0135e-01, -2.0444e-01, -3.2241e-01, -1.3135e+00,\n",
      "         -2.1535e+00,  1.3010e+00, -1.1886e+00,  5.0758e-01,  6.4995e-01,\n",
      "          2.4967e-01,  8.5328e-01, -1.0470e+00,  3.6077e-01, -1.0399e+00,\n",
      "          4.7186e-01,  1.4362e+00,  1.3697e+00,  2.3435e+00,  2.0760e+00,\n",
      "         -6.7432e-01,  4.3421e-01, -1.6195e+00,  1.0874e+00,  4.3373e-01,\n",
      "         -1.7185e+00,  1.6826e+00,  5.9177e-01,  5.5661e-02,  1.1926e+00,\n",
      "          1.4625e+00,  1.8380e+00, -1.7371e+00,  1.8458e+00,  1.2332e+00,\n",
      "          2.8690e-01, -7.3725e-02, -1.2498e+00, -3.5504e-01,  1.2384e-01,\n",
      "          2.4143e-01,  4.6618e-01, -7.0633e-01,  2.6069e+00, -4.0349e-01,\n",
      "          6.0958e-01,  1.5780e+00,  1.1124e+00, -2.2234e-02,  1.4404e+00,\n",
      "         -7.6653e-01, -7.5146e-01, -2.1208e-02, -2.2548e-01,  3.0530e-01,\n",
      "          1.2181e+00,  6.4914e-01, -1.0059e+00, -6.9123e-01, -6.0400e-01,\n",
      "          8.7988e-01,  7.2615e-01, -5.9301e-01,  8.1734e-02,  1.9508e+00,\n",
      "         -1.0608e+00, -1.1425e+00,  5.5535e-02, -1.5507e-02, -6.5314e-01,\n",
      "          3.4791e-01,  3.9482e-01, -4.0634e-02,  4.9027e-01, -6.1308e-01,\n",
      "          2.3830e+00,  1.7501e+00,  1.6037e+00, -2.3054e-01, -6.9087e-01,\n",
      "         -7.3704e-01,  5.7109e-01, -5.7745e-01, -6.1861e-01, -6.9915e-02,\n",
      "          9.5811e-01, -1.0340e+00,  2.5930e-01, -1.1497e+00,  8.3521e-01,\n",
      "         -2.3196e+00,  2.9622e-01, -1.6112e+00, -1.5809e-01, -4.5241e-01,\n",
      "          6.3535e-02, -4.9213e-01,  1.6051e-01, -1.2753e+00, -8.6380e-01,\n",
      "          5.9742e-01, -9.0867e-01, -5.3866e-01,  1.8668e-01,  2.2578e-01,\n",
      "         -9.8627e-01,  4.8050e-01,  8.3273e-02, -6.8763e-01,  5.4994e-01,\n",
      "          1.4774e+00, -3.3876e-01, -1.6082e-01,  4.4653e-01, -2.2865e-01,\n",
      "          1.2766e+00,  7.8792e-01, -1.5241e+00,  2.5297e-01,  7.6860e-01,\n",
      "         -1.2407e+00,  5.5581e-01, -7.0763e-02,  4.2751e-01,  1.6400e+00,\n",
      "         -2.9417e-01,  2.0794e-01,  1.1824e+00,  4.1689e-01,  5.7601e-01,\n",
      "          2.5872e-01, -3.1905e-01,  1.1036e+00, -7.1600e-01, -8.1995e-01,\n",
      "          2.7583e-02,  1.9132e-01,  1.1593e+00, -1.5700e+00,  7.9584e-01,\n",
      "          6.6241e-01, -6.6946e-01, -8.5659e-01, -7.3785e-01, -1.2224e+00,\n",
      "         -1.3587e-01,  1.8006e-01,  4.3486e-02,  1.0260e+00,  8.2751e-01,\n",
      "          3.3945e-01, -7.0344e-01, -6.8660e-01,  3.6250e-01,  2.1860e-01,\n",
      "         -9.9059e-01,  7.7393e-01, -5.1216e-01, -6.6889e-01, -1.5791e+00,\n",
      "         -3.8593e-01,  5.7087e-01,  1.7539e+00, -1.0083e+00,  3.0315e-01,\n",
      "          2.7635e-01,  7.4644e-01,  8.9763e-01,  8.6415e-01, -4.1457e-01,\n",
      "         -2.8834e-01,  5.5610e-01, -2.4269e-01,  6.6872e-02, -7.5719e-01,\n",
      "         -4.1992e-01,  8.9259e-02,  1.0694e+00, -3.4959e-01, -5.8200e-01,\n",
      "          1.3050e+00,  4.4861e-01,  7.9520e-01,  1.1824e+00,  7.4469e-01,\n",
      "         -1.3552e+00, -8.1269e-01,  6.7879e-02, -2.5910e-01, -4.9795e-01,\n",
      "         -1.6537e+00,  1.2409e+00, -3.8919e-01, -6.2733e-01,  5.3340e-01,\n",
      "          3.1197e-01, -1.0949e+00,  9.3241e-01, -2.0582e+00, -5.6562e-01,\n",
      "         -4.3894e-01, -2.3465e+00, -1.3499e+00, -1.0541e+00,  3.0900e-01,\n",
      "         -1.6259e+00, -6.0962e-01, -1.7892e+00,  8.9216e-01, -6.2808e-02,\n",
      "         -4.9078e-01, -2.0545e-01,  3.4619e-01, -4.5761e-01,  4.2647e-01,\n",
      "          1.3862e+00, -1.1009e+00, -2.3855e-01, -1.7933e-02,  1.5218e-01,\n",
      "          9.4017e-01, -1.5379e+00, -4.4511e-02,  1.5143e+00, -6.3650e-01,\n",
      "         -4.5859e-01,  4.4292e-01, -1.1376e-01, -2.4610e-01,  2.5311e-01,\n",
      "          9.1204e-01,  1.1103e+00, -9.1452e-01, -1.4718e-01,  2.9225e-01,\n",
      "          7.5579e-02, -5.7146e-01, -8.0084e-01, -8.1852e-01,  1.6144e+00,\n",
      "          5.1712e-01, -9.9424e-01,  4.5371e-01, -3.4536e-01, -4.3438e-02,\n",
      "         -2.6694e-01, -5.7945e-01, -1.9680e+00, -5.7689e-01,  9.3560e-01,\n",
      "         -8.4567e-01, -4.8808e-01, -2.4877e-02,  4.1437e-01,  1.1407e+00,\n",
      "         -8.9786e-01,  7.0606e-01,  1.5523e+00,  1.4067e+00, -5.8343e-01,\n",
      "          2.9642e-01,  4.8366e-01, -1.6396e+00, -1.3200e+00, -2.8806e-01,\n",
      "         -1.9678e-02, -2.7240e-01,  1.1921e+00, -3.1160e-01,  2.5140e-01,\n",
      "          2.3857e-01, -2.6608e-01, -9.8203e-01,  3.0217e-01,  2.9198e-01,\n",
      "         -4.9173e-01, -1.1091e+00,  7.8339e-02,  6.5648e-01, -7.3056e-01,\n",
      "         -1.1607e+00,  4.4050e-01,  5.4307e-02, -7.3124e-01,  4.9008e-02,\n",
      "         -3.6014e-01, -6.9746e-01,  4.2394e-01,  5.3448e-03,  2.9227e-02,\n",
      "         -3.0472e+00,  7.9899e-01, -9.7815e-01,  3.3699e-01, -1.4423e+00,\n",
      "          5.4428e-03,  7.4292e-01,  1.8378e-01, -2.8961e-01, -9.1568e-01,\n",
      "         -6.1471e-01,  6.3417e-01,  1.6542e+00, -1.9346e+00,  1.7409e+00,\n",
      "          5.7227e-01,  2.4143e-01, -1.9666e+00, -2.3078e-01, -1.3972e+00,\n",
      "          7.6799e-01, -3.3670e-01, -7.8270e-02, -1.7090e-01,  5.4934e-01,\n",
      "          7.3326e-01,  1.3505e+00,  6.6089e-01,  1.7695e-01,  1.1392e-01,\n",
      "          9.6173e-01, -9.4814e-01,  4.8956e-01, -3.8425e-01, -1.1529e-01,\n",
      "         -1.3180e+00,  7.7887e-01, -1.3846e+00,  4.5356e-01, -2.5525e-01,\n",
      "          6.6729e-01, -9.3247e-01,  1.0195e+00,  3.1875e-01, -1.1499e+00,\n",
      "         -1.2154e+00,  1.3834e+00,  4.5537e-01, -7.5246e-01, -1.3794e+00,\n",
      "         -4.1995e-03,  1.4265e+00, -7.3177e-01, -9.7342e-01,  5.4252e-02,\n",
      "         -6.9309e-01,  6.0551e-01, -1.8706e+00,  2.6376e-01, -3.3569e-01,\n",
      "         -1.9032e+00, -1.0535e-01,  1.1287e+00,  6.6733e-01,  7.6950e-01,\n",
      "          1.2614e+00, -2.9590e-01, -2.4139e-01,  1.2064e+00, -1.3174e+00,\n",
      "          9.7743e-01,  5.1056e-02]])\n",
      "tensor([[ 0.6879, -0.1363,  0.7379,  ...,  0.5002, -0.0112,  0.2864],\n",
      "        [ 0.6879, -0.1363,  0.7379,  ...,  0.5002, -0.0112,  0.2864],\n",
      "        [ 0.6879, -0.1363,  0.7379,  ...,  0.5002, -0.0112,  0.2864],\n",
      "        ...,\n",
      "        [ 0.6879, -0.1363,  0.7379,  ...,  0.5002, -0.0112,  0.2864],\n",
      "        [ 0.6879, -0.1363,  0.7379,  ...,  0.5002, -0.0112,  0.2864],\n",
      "        [ 0.6879, -0.1363,  0.7379,  ...,  0.5002, -0.0112,  0.2864]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(a[0])\n",
    "print(b[0])\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
